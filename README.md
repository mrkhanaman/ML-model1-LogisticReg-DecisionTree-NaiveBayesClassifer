# Machine Learning Model 1: Classification Model using Logisting Regression, Decision Tree Classifer and Naive Bayes Classifier.

---

## ðŸ“– Overview

This repository contains the solution for ML Model Classification Model using Logisting Regression, Decision Tree Classifer and Naive Bayes Classifier. The model demonstrates the application of data science concepts to solve a practical classification problem. The task involves identifying individuals who can afford to purchase a new iPhone based on their demographic and financial data.

---

## ðŸ“ Problem Statement and Variables

- **Problem Statement:**  
  Predict whether a user can afford to purchase an iPhone based on their attributes such as age, estimated salary, gender, and bank balance.

- **Independent Variable:**  
  - `Purchased`: Indicates whether the user purchased the iPhone (target variable).  

- **Dependent Variables:**  
  - `Gender`: Binary variable indicating the userâ€™s gender.  
  - `Age`: Age of the user in years.  
  - `EstimatedSalary`: The estimated annual salary of the user.  
  - `BankBalance`: The total bank balance available for the user.  

Each variable contributes uniquely to the prediction task, playing a critical role in model training and evaluation.

---

## âš™ï¸ Models Used

Three classification models were implemented to address the problem statement:

1. **Logistic Regression**  
   - Predicts the probability of a binary outcome using a logistic function.

2. **Decision Tree Classifier**  
   - A non-parametric supervised learning method that splits data into subsets based on feature values.

3. **Naive Bayes Classifier**  
   - A probabilistic model based on Bayes' theorem, assuming independence among features.

All models were trained and tested on the dataset, using between 4 and 8 features as specified in the assignment.

---

## ðŸ“Š Evaluation Metric

The **Confusion Matrix** was used as the primary evaluation metric. This method was chosen due to its ability to:

- Provide a detailed breakdown of **True Positives (TP)**, **True Negatives (TN)**, **False Positives (FP)**, and **False Negatives (FN)**.
- Enable a comprehensive assessment of model performance.
- Highlight areas for potential improvement.

---

## ðŸš€ Conclusion

This ML Model showcases the practical application of data science techniques, focusing on:

- Feature selection and preprocessing.
- Implementation of multiple classification algorithms.
- Effective evaluation and comparison of model performance.

The project reinforces theoretical knowledge and hones practical skills for solving real-world classification problems.

---

> **Note:** Feel free to explore the repository to access the code, models, and evaluation results.

